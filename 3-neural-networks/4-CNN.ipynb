{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad 操作\n",
    "\n",
    "- **calc_pad_dims_2D**: Compute the padding necessary to ensure that convolving `X` with a 2D kernel of shape `kernel_shape` and stride `stride` produces outputs with dimension `out_dim`.\n",
    "- **calc_pad_dims_1D**: Compute the padding necessary to ensure that convolving `X` with a 1D kernel of shape `kernel_shape` and stride `stride` produces outputs with length `l_out`.\n",
    "- **pad1D**: Zero-pad a 3D input volume `X` along the second dimension.\n",
    "- **pad2D**: Zero-pad a 4D input volume `X` along the second and third dimensions.\n",
    "- **dilate**: Dilate the 4D volume `X` by `d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pad_dims_2D(X_shape, out_dim, kernel_shape, stride, dilation=0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_shape : tuple of `(n_ex, in_rows, in_cols, in_ch)`\n",
    "        Dimensions of the input volume. Padding is applied to `in_rows` and\n",
    "        `in_cols`.\n",
    "    out_dim : tuple of `(out_rows, out_cols)`\n",
    "        The desired dimension of an output example after applying the\n",
    "        convolution.\n",
    "    kernel_shape : 2-tuple\n",
    "        The dimension of the 2D convolution kernel.\n",
    "    stride : int\n",
    "        The stride for the convolution kernel.\n",
    "    dilation : int\n",
    "        Number of pixels inserted between kernel elements. Default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    padding_dims : 4-tuple\n",
    "        Padding dims for `X`. Organized as (left, right, up, down)\n",
    "    \"\"\"\n",
    "    if not isinstance(X_shape, tuple):\n",
    "        raise ValueError(\"`X_shape` must be of type tuple\")\n",
    "\n",
    "    if not isinstance(out_dim, tuple):\n",
    "        raise ValueError(\"`out_dim` must be of type tuple\")\n",
    "\n",
    "    if not isinstance(kernel_shape, tuple):\n",
    "        raise ValueError(\"`kernel_shape` must be of type tuple\")\n",
    "\n",
    "    if not isinstance(stride, int):\n",
    "        raise ValueError(\"`stride` must be of type int\")\n",
    "\n",
    "    d = dilation\n",
    "    fr, fc = kernel_shape\n",
    "    out_rows, out_cols = out_dim\n",
    "    n_ex, in_rows, in_cols, in_ch = X_shape\n",
    "\n",
    "    # update effective filter shape based on dilation factor\n",
    "    _fr, _fc = fr * (d + 1) - d, fc * (d + 1) - d\n",
    "\n",
    "    pr = int((stride * (out_rows - 1) + _fr - in_rows) / 2)\n",
    "    pc = int((stride * (out_cols - 1) + _fc - in_cols) / 2)\n",
    "\n",
    "    out_rows1 = int(1 + (in_rows + 2 * pr - _fr) / stride)\n",
    "    out_cols1 = int(1 + (in_cols + 2 * pc - _fc) / stride)\n",
    "\n",
    "    # add asymmetric padding pixels to right / bottom\n",
    "    pr1, pr2 = pr, pr\n",
    "    if out_rows1 == out_rows - 1:\n",
    "        pr1, pr2 = pr, pr + 1\n",
    "    elif out_rows1 != out_rows:\n",
    "        raise AssertionError\n",
    "\n",
    "    pc1, pc2 = pc, pc\n",
    "    if out_cols1 == out_cols - 1:\n",
    "        pc1, pc2 = pc, pc + 1\n",
    "    elif out_cols1 != out_cols:\n",
    "        raise AssertionError\n",
    "\n",
    "    if any(np.array([pr1, pr2, pc1, pc2]) < 0):\n",
    "        raise ValueError(\n",
    "            \"Padding cannot be less than 0. Got: {}\".format((pr1, pr2, pc1, pc2))\n",
    "        )\n",
    "    return (pr1, pr2, pc1, pc2)\n",
    "\n",
    "\n",
    "def calc_pad_dims_1D(X_shape, l_out, kernel_width, stride, dilation=0, causal=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_shape : tuple of `(n_ex, l_in, in_ch)`\n",
    "        Dimensions of the input volume. Padding is applied on either side of\n",
    "        `l_in`.\n",
    "    l_out : int\n",
    "        The desired length an output example after applying the convolution.\n",
    "    kernel_width : int\n",
    "        The width of the 1D convolution kernel.\n",
    "    stride : int\n",
    "        The stride for the convolution kernel.\n",
    "    dilation : int\n",
    "        Number of pixels inserted between kernel elements. Default is 0.\n",
    "    causal : bool\n",
    "        Whether to compute the padding dims for a regular or causal\n",
    "        convolution. If causal, padding is added only to the left side of the\n",
    "        sequence. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    padding_dims : 2-tuple\n",
    "        Padding dims for X. Organized as (left, right)\n",
    "    \"\"\"\n",
    "    if not isinstance(X_shape, tuple):\n",
    "        raise ValueError(\"`X_shape` must be of type tuple\")\n",
    "\n",
    "    if not isinstance(l_out, int):\n",
    "        raise ValueError(\"`l_out` must be of type int\")\n",
    "\n",
    "    if not isinstance(kernel_width, int):\n",
    "        raise ValueError(\"`kernel_width` must be of type int\")\n",
    "\n",
    "    if not isinstance(stride, int):\n",
    "        raise ValueError(\"`stride` must be of type int\")\n",
    "\n",
    "    d = dilation\n",
    "    fw = kernel_width\n",
    "    n_ex, l_in, in_ch = X_shape\n",
    "\n",
    "    # update effective filter shape based on dilation factor\n",
    "    _fw = fw * (d + 1) - d\n",
    "    total_pad = int((stride * (l_out - 1) + _fw - l_in))\n",
    "\n",
    "    if not causal:\n",
    "        pw = total_pad // 2\n",
    "        l_out1 = int(1 + (l_in + 2 * pw - _fw) / stride)\n",
    "\n",
    "        # add asymmetric padding pixels to right / bottom\n",
    "        pw1, pw2 = pw, pw\n",
    "        if l_out1 == l_out - 1:\n",
    "            pw1, pw2 = pw, pw + 1\n",
    "        elif l_out1 != l_out:\n",
    "            raise AssertionError\n",
    "\n",
    "    if causal:\n",
    "        # if this is a causal convolution, only pad the left side of the\n",
    "        # sequence\n",
    "        pw1, pw2 = total_pad, 0\n",
    "        l_out1 = int(1 + (l_in + total_pad - _fw) / stride)\n",
    "        assert l_out1 == l_out\n",
    "\n",
    "    if any(np.array([pw1, pw2]) < 0):\n",
    "        raise ValueError(\"Padding cannot be less than 0. Got: {}\".format((pw1, pw2)))\n",
    "    return (pw1, pw2)\n",
    "\n",
    "\n",
    "def pad1D(X, pad, kernel_width=None, stride=None, dilation=0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, l_in, in_ch)`\n",
    "        Input volume. Padding is applied to `l_in`.\n",
    "    pad : tuple, int, or {'same', 'causal'}\n",
    "        The padding amount. If 'same', add padding to ensure that the output\n",
    "        length of a 1D convolution with a kernel of `kernel_shape` and stride\n",
    "        `stride` is the same as the input length.  If 'causal' compute padding\n",
    "        such that the output both has the same length as the input AND\n",
    "        ``output[t]`` does not depend on ``input[t + 1:]``. If 2-tuple,\n",
    "        specifies the number of padding columns to add on each side of the\n",
    "        sequence.\n",
    "    kernel_width : int\n",
    "        The dimension of the 2D convolution kernel. Only relevant if p='same'\n",
    "        or 'causal'. Default is None.\n",
    "    stride : int\n",
    "        The stride for the convolution kernel. Only relevant if p='same' or\n",
    "        'causal'. Default is None.\n",
    "    dilation : int\n",
    "        The dilation of the convolution kernel. Only relevant if p='same' or\n",
    "        'causal'. Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_pad : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, padded_seq, in_channels)`\n",
    "        The padded output volume\n",
    "    p : 2-tuple\n",
    "        The number of 0-padded columns added to the (left, right) of the sequences\n",
    "        in `X`.\n",
    "    \"\"\"\n",
    "    p = pad\n",
    "    if isinstance(p, int):\n",
    "        p = (p, p)\n",
    "\n",
    "    if isinstance(p, tuple):\n",
    "        X_pad = np.pad(\n",
    "            X,\n",
    "            pad_width=((0, 0), (p[0], p[1]), (0, 0)),\n",
    "            mode=\"constant\",\n",
    "            constant_values=0,\n",
    "        )\n",
    "\n",
    "    # compute the correct padding dims for a 'same' or 'causal' convolution\n",
    "    if p in [\"same\", \"causal\"] and kernel_width and stride:\n",
    "        causal = p == \"causal\"\n",
    "        p = calc_pad_dims_1D(\n",
    "            X.shape, X.shape[1], kernel_width, stride, causal=causal, dilation=dilation\n",
    "        )\n",
    "        X_pad, p = pad1D(X, p)\n",
    "\n",
    "    return X_pad, p\n",
    "\n",
    "\n",
    "def pad2D(X, pad, kernel_shape=None, stride=None, dilation=0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, in_rows, in_cols, in_ch)`\n",
    "        Input volume. Padding is applied to `in_rows` and `in_cols`.\n",
    "    pad : tuple, int, or 'same'\n",
    "        The padding amount. If 'same', add padding to ensure that the output of\n",
    "        a 2D convolution with a kernel of `kernel_shape` and stride `stride`\n",
    "        has the same dimensions as the input.  If 2-tuple, specifies the number\n",
    "        of padding rows and colums to add *on both sides* of the rows/columns\n",
    "        in `X`. If 4-tuple, specifies the number of rows/columns to add to the\n",
    "        top, bottom, left, and right of the input volume.\n",
    "    kernel_shape : 2-tuple\n",
    "        The dimension of the 2D convolution kernel. Only relevant if p='same'.\n",
    "        Default is None.\n",
    "    stride : int\n",
    "        The stride for the convolution kernel. Only relevant if p='same'.\n",
    "        Default is None.\n",
    "    dilation : int\n",
    "        The dilation of the convolution kernel. Only relevant if p='same'.\n",
    "        Default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_pad : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, padded_in_rows, padded_in_cols, in_channels)`\n",
    "        The padded output volume.\n",
    "    p : 4-tuple\n",
    "        The number of 0-padded rows added to the (top, bottom, left, right) of\n",
    "        `X`.\n",
    "    \"\"\"\n",
    "    p = pad\n",
    "    if isinstance(p, int):\n",
    "        p = (p, p, p, p)\n",
    "\n",
    "    if isinstance(p, tuple):\n",
    "        if len(p) == 2:\n",
    "            p = (p[0], p[0], p[1], p[1])\n",
    "\n",
    "        X_pad = np.pad(\n",
    "            X,\n",
    "            pad_width=((0, 0), (p[0], p[1]), (p[2], p[3]), (0, 0)),\n",
    "            mode=\"constant\",\n",
    "            constant_values=0,\n",
    "        )\n",
    "\n",
    "    # compute the correct padding dims for a 'same' convolution\n",
    "    if p == \"same\" and kernel_shape and stride is not None:\n",
    "        p = calc_pad_dims_2D(\n",
    "            X.shape, X.shape[1:3], kernel_shape, stride, dilation=dilation\n",
    "        )\n",
    "        X_pad, p = pad2D(X, p)\n",
    "    return X_pad, p\n",
    "\n",
    "\n",
    "def dilate(X, d):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, in_rows, in_cols, in_ch)`\n",
    "        Input volume.\n",
    "    d : int\n",
    "        The number of 0-rows to insert between each adjacent row + column in `X`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Xd : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, out_rows, out_cols, out_ch)`\n",
    "        The dilated array where\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            \\\\text{out_rows}  &=  \\\\text{in_rows} + d(\\\\text{in_rows} - 1) \\\\\\\\\n",
    "            \\\\text{out_cols}  &=  \\\\text{in_cols} + d (\\\\text{in_cols} - 1)\n",
    "    \"\"\"\n",
    "    n_ex, in_rows, in_cols, n_in = X.shape\n",
    "    r_ix = np.repeat(np.arange(1, in_rows), d)\n",
    "    c_ix = np.repeat(np.arange(1, in_cols), d)\n",
    "    Xd = np.insert(X, r_ix, 0, axis=1)\n",
    "    Xd = np.insert(Xd, c_ix, 0, axis=2)\n",
    "    return Xd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23]\n",
      " [24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35]]\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  3  4  5  0  0  0]\n",
      " [ 0  0  0  6  7  8  9 10 11  0  0  0]\n",
      " [ 0  0  0 12 13 14 15 16 17  0  0  0]\n",
      " [ 0  0  0 18 19 20 21 22 23  0  0  0]\n",
      " [ 0  0  0 24 25 26 27 28 29  0  0  0]\n",
      " [ 0  0  0 30 31 32 33 34 35  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(36).reshape(1, 6, 6, 1)\n",
    "a_pad, _ = pad2D(a, 3)\n",
    "print(a.reshape(6,6))\n",
    "print(a_pad.reshape(a_pad.shape[1], a_pad.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _im2col_indices(X_shape, fr, fc, p, s, d=0):\n",
    "    \"\"\"\n",
    "    Helper function that computes indices into X in prep for columnization in\n",
    "    :func:`im2col`.\n",
    "\n",
    "    Code extended from Andrej Karpathy's `im2col.py`\n",
    "    \"\"\"\n",
    "    pr1, pr2, pc1, pc2 = p\n",
    "    n_ex, n_in, in_rows, in_cols = X_shape\n",
    "\n",
    "    # adjust effective filter size to account for dilation\n",
    "    _fr, _fc = fr * (d + 1) - d, fc * (d + 1) - d\n",
    "\n",
    "    out_rows = (in_rows + pr1 + pr2 - _fr) // s + 1\n",
    "    out_cols = (in_cols + pc1 + pc2 - _fc) // s + 1\n",
    "\n",
    "    if any([out_rows <= 0, out_cols <= 0]):\n",
    "        raise ValueError(\n",
    "            \"Dimension mismatch during convolution: \"\n",
    "            \"out_rows = {}, out_cols = {}\".format(out_rows, out_cols)\n",
    "        )\n",
    "\n",
    "    # i1/j1 : row/col templates\n",
    "    # i0/j0 : n. copies (len) and offsets (values) for row/col templates\n",
    "    i0 = np.repeat(np.arange(fr), fc)\n",
    "    i0 = np.tile(i0, n_in) * (d + 1)\n",
    "    i1 = s * np.repeat(np.arange(out_rows), out_cols)\n",
    "    j0 = np.tile(np.arange(fc), fr * n_in) * (d + 1)\n",
    "    j1 = s * np.tile(np.arange(out_cols), out_rows)\n",
    "\n",
    "    # i.shape = (fr * fc * n_in, out_height * out_width)\n",
    "    # j.shape = (fr * fc * n_in, out_height * out_width)\n",
    "    # k.shape = (fr * fc * n_in, 1)\n",
    "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "    k = np.repeat(np.arange(n_in), fr * fc).reshape(-1, 1)\n",
    "    return k, i, j\n",
    "\n",
    "\n",
    "def im2col(X, W_shape, pad, stride, dilation=0):\n",
    "    \"\"\"\n",
    "    Pads and rearrange overlapping windows of the input volume into column\n",
    "    vectors, returning the concatenated padded vectors in a matrix `X_col`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    A NumPy reimagining of MATLAB's ``im2col`` 'sliding' function.\n",
    "\n",
    "    Code extended from Andrej Karpathy's ``im2col.py``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, in_rows, in_cols, in_ch)`\n",
    "        Input volume (not padded).\n",
    "    W_shape: 4-tuple containing `(kernel_rows, kernel_cols, in_ch, out_ch)`\n",
    "        The dimensions of the weights/kernels in the present convolutional\n",
    "        layer.\n",
    "    pad : tuple, int, or 'same'\n",
    "        The padding amount. If 'same', add padding to ensure that the output of\n",
    "        a 2D convolution with a kernel of `kernel_shape` and stride `stride`\n",
    "        produces an output volume of the same dimensions as the input.  If\n",
    "        2-tuple, specifies the number of padding rows and colums to add *on both\n",
    "        sides* of the rows/columns in X. If 4-tuple, specifies the number of\n",
    "        rows/columns to add to the top, bottom, left, and right of the input\n",
    "        volume.\n",
    "    stride : int\n",
    "        The stride of each convolution kernel\n",
    "    dilation : int\n",
    "        Number of pixels inserted between kernel elements. Default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_col : :py:class:`ndarray <numpy.ndarray>` of shape (Q, Z)\n",
    "        The reshaped input volume where where:\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            Q  &=  \\\\text{kernel_rows} \\\\times \\\\text{kernel_cols} \\\\times \\\\text{n_in} \\\\\\\\\n",
    "            Z  &=  \\\\text{n_ex} \\\\times \\\\text{out_rows} \\\\times \\\\text{out_cols}\n",
    "    \"\"\"\n",
    "    fr, fc, n_in, n_out = W_shape\n",
    "    s, p, d = stride, pad, dilation\n",
    "    n_ex, in_rows, in_cols, n_in = X.shape\n",
    "\n",
    "    # zero-pad the input\n",
    "    X_pad, p = pad2D(X, p, W_shape[:2], stride=s, dilation=d)\n",
    "    pr1, pr2, pc1, pc2 = p\n",
    "\n",
    "    # shuffle to have channels as the first dim\n",
    "    X_pad = X_pad.transpose(0, 3, 1, 2)\n",
    "\n",
    "    # get the indices for im2col\n",
    "    k, i, j = _im2col_indices((n_ex, n_in, in_rows, in_cols), fr, fc, p, s, d)\n",
    "\n",
    "    X_col = X_pad[:, k, i, j]\n",
    "    X_col = X_col.transpose(1, 2, 0).reshape(fr * fc * n_in, -1)\n",
    "    return X_col, p\n",
    "\n",
    "\n",
    "def col2im(X_col, X_shape, W_shape, pad, stride, dilation=0):\n",
    "    \"\"\"\n",
    "    Take columns of a 2D matrix and rearrange them into the blocks/windows of\n",
    "    a 4D image volume.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    A NumPy reimagining of MATLAB's ``col2im`` 'sliding' function.\n",
    "\n",
    "    Code extended from Andrej Karpathy's ``im2col.py``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_col : :py:class:`ndarray <numpy.ndarray>` of shape `(Q, Z)`\n",
    "        The columnized version of `X` (assumed to include padding)\n",
    "    X_shape : 4-tuple containing `(n_ex, in_rows, in_cols, in_ch)`\n",
    "        The original dimensions of `X` (not including padding)\n",
    "    W_shape: 4-tuple containing `(kernel_rows, kernel_cols, in_ch, out_ch)`\n",
    "        The dimensions of the weights in the present convolutional layer\n",
    "    pad : 4-tuple of `(left, right, up, down)`\n",
    "        Number of zero-padding rows/cols to add to `X`\n",
    "    stride : int\n",
    "        The stride of each convolution kernel\n",
    "    dilation : int\n",
    "        Number of pixels inserted between kernel elements. Default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    img : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, in_rows, in_cols, in_ch)`\n",
    "        The reshaped `X_col` input matrix\n",
    "    \"\"\"\n",
    "    if not (isinstance(pad, tuple) and len(pad) == 4):\n",
    "        raise TypeError(\"pad must be a 4-tuple, but got: {}\".format(pad))\n",
    "\n",
    "    s, d = stride, dilation\n",
    "    pr1, pr2, pc1, pc2 = pad\n",
    "    fr, fc, n_in, n_out = W_shape\n",
    "    n_ex, in_rows, in_cols, n_in = X_shape\n",
    "\n",
    "    X_pad = np.zeros((n_ex, n_in, in_rows + pr1 + pr2, in_cols + pc1 + pc2))\n",
    "    k, i, j = _im2col_indices((n_ex, n_in, in_rows, in_cols), fr, fc, pad, s, d)\n",
    "\n",
    "    X_col_reshaped = X_col.reshape(n_in * fr * fc, -1, n_ex)\n",
    "    X_col_reshaped = X_col_reshaped.transpose(2, 0, 1)\n",
    "\n",
    "    np.add.at(X_pad, (slice(None), k, i, j), X_col_reshaped)\n",
    "\n",
    "    pr2 = None if pr2 == 0 else -pr2\n",
    "    pc2 = None if pc2 == 0 else -pc2\n",
    "    return X_pad[:, :, pr1:pr2, pc1:pc2]\n",
    "\n",
    "\n",
    "def conv2D(X, W, stride, pad, dilation=0):\n",
    "    \"\"\"\n",
    "    A faster (but more memory intensive) implementation of the 2D \"convolution\"\n",
    "    (technically, cross-correlation) of input `X` with a collection of kernels in\n",
    "    `W`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Relies on the :func:`im2col` function to perform the convolution as a single\n",
    "    matrix multiplication.\n",
    "\n",
    "    For a helpful diagram, see Pete Warden's 2015 blogpost [1].\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Warden (2015). \"Why GEMM is at the heart of deep learning,\"\n",
    "       https://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, in_rows, in_cols, in_ch)`\n",
    "        Input volume (unpadded).\n",
    "    W: :py:class:`ndarray <numpy.ndarray>` of shape `(kernel_rows, kernel_cols, in_ch, out_ch)`\n",
    "        A volume of convolution weights/kernels for a given layer.\n",
    "    stride : int\n",
    "        The stride of each convolution kernel.\n",
    "    pad : tuple, int, or 'same'\n",
    "        The padding amount. If 'same', add padding to ensure that the output of\n",
    "        a 2D convolution with a kernel of `kernel_shape` and stride `stride`\n",
    "        produces an output volume of the same dimensions as the input.  If\n",
    "        2-tuple, specifies the number of padding rows and colums to add *on both\n",
    "        sides* of the rows/columns in `X`. If 4-tuple, specifies the number of\n",
    "        rows/columns to add to the top, bottom, left, and right of the input\n",
    "        volume.\n",
    "    dilation : int\n",
    "        Number of pixels inserted between kernel elements. Default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Z : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, out_rows, out_cols, out_ch)`\n",
    "        The covolution of `X` with `W`.\n",
    "    \"\"\"\n",
    "    s, d = stride, dilation\n",
    "    _, p = pad2D(X, pad, W.shape[:2], s, dilation=dilation)\n",
    "\n",
    "    pr1, pr2, pc1, pc2 = p\n",
    "    fr, fc, in_ch, out_ch = W.shape\n",
    "    n_ex, in_rows, in_cols, in_ch = X.shape\n",
    "\n",
    "    # update effective filter shape based on dilation factor\n",
    "    _fr, _fc = fr * (d + 1) - d, fc * (d + 1) - d\n",
    "\n",
    "    # compute the dimensions of the convolution output\n",
    "    out_rows = int((in_rows + pr1 + pr2 - _fr) / s + 1)\n",
    "    out_cols = int((in_cols + pc1 + pc2 - _fc) / s + 1)\n",
    "\n",
    "    # convert X and W into the appropriate 2D matrices and take their product\n",
    "    X_col, _ = im2col(X, W.shape, p, s, d)\n",
    "    W_col = W.transpose(3, 2, 0, 1).reshape(out_ch, -1)\n",
    "\n",
    "    Z = (W_col @ X_col).reshape(out_ch, out_rows, out_cols, n_ex).transpose(3, 1, 2, 0)\n",
    "\n",
    "    return Z\n",
    "\n",
    "\n",
    "def conv1D(X, W, stride, pad, dilation=0):\n",
    "    \"\"\"\n",
    "    A faster (but more memory intensive) implementation of a 1D \"convolution\"\n",
    "    (technically, cross-correlation) of input `X` with a collection of kernels in\n",
    "    `W`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Relies on the :func:`im2col` function to perform the convolution as a single\n",
    "    matrix multiplication.\n",
    "\n",
    "    For a helpful diagram, see Pete Warden's 2015 blogpost [1].\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Warden (2015). \"Why GEMM is at the heart of deep learning,\"\n",
    "       https://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, l_in, in_ch)`\n",
    "        Input volume (unpadded)\n",
    "    W: :py:class:`ndarray <numpy.ndarray>` of shape `(kernel_width, in_ch, out_ch)`\n",
    "        A volume of convolution weights/kernels for a given layer\n",
    "    stride : int\n",
    "        The stride of each convolution kernel\n",
    "    pad : tuple, int, or 'same'\n",
    "        The padding amount. If 'same', add padding to ensure that the output of\n",
    "        a 1D convolution with a kernel of `kernel_shape` and stride `stride`\n",
    "        produces an output volume of the same dimensions as the input.  If\n",
    "        2-tuple, specifies the number of padding colums to add *on both sides*\n",
    "        of the columns in X.\n",
    "    dilation : int\n",
    "        Number of pixels inserted between kernel elements. Default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Z : :py:class:`ndarray <numpy.ndarray>` of shape `(n_ex, l_out, out_ch)`\n",
    "        The convolution of X with W.\n",
    "    \"\"\"\n",
    "    _, p = pad1D(X, pad, W.shape[0], stride, dilation=dilation)\n",
    "\n",
    "    # add a row dimension to X to permit us to use im2col/col2im\n",
    "    X2D = np.expand_dims(X, axis=1)\n",
    "    W2D = np.expand_dims(W, axis=0)\n",
    "    p2D = (0, 0, p[0], p[1])\n",
    "    Z2D = conv2D(X2D, W2D, stride, p2D, dilation)\n",
    "\n",
    "    # drop the row dimension\n",
    "    return np.squeeze(Z2D, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23]\n",
      " [24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35]]\n",
      "[[ 63.  72.  81.  90.]\n",
      " [117. 126. 135. 144.]\n",
      " [171. 180. 189. 198.]\n",
      " [225. 234. 243. 252.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(36).reshape(1, 6, 6, 1)\n",
    "a_conv = conv2D(a, np.ones((3, 3, 1, 1)), 1, 0)\n",
    "print(a.reshape(a.shape[1], a.shape[2]))\n",
    "print(a_conv.reshape(a_conv.shape[1], a_conv.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (jupyter)",
   "language": "python",
   "name": "pycharm-34f9d306"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
